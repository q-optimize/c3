Open-loop optimal control
^^^^^^^^^^^^^^^^^^^^^^^^^

In order to improve the gate from the previous example :ref:`setup-example`,
we create the optimizer object for open-loop optimal control. Examining the
previous dynamics
.. image:: dyn_singleX.png

in addition to over-rotation, we notice some leakage
into the :math:`|2,0>` state and enable a DRAG option.
Details on DRAG can be found
`here <https://arxiv.org/abs/1809.04919>`_. The main principle is adding a
phase-shifted component proportional to the derivative of the original
signal. With automatic differentiation, our AWG can perform this
operation automatically for arbitrary shapes.

.. code-block:: python

    generator.devices['awg'].options = 'drag_2'

At the moment there are two implementations of DRAG, variant 2 is
independent of the AWG resolution.

To define which parameters we optimize, we write the gateset_opt_map, a
nested list of tuples that identifies each parameter.

.. code-block:: python

    opt_gates = ["X90p:Id"]
    gateset_opt_map=[
        [
          ("X90p:Id", "d1", "gauss", "amp"),
        ],
        [
          ("X90p:Id", "d1", "gauss", "freq_offset"),
        ],
        [
          ("X90p:Id", "d1", "gauss", "xy_angle"),
        ],
        [
          ("X90p:Id", "d1", "gauss", "delta"),
        ]
    ]

We can look at the parameter values this opt_map specified with

.. code-block:: python

    exp.gateset.get_parameters(gateset_opt_map)




.. parsed-literal::

    [<tf.Tensor: shape=(), dtype=float64, numpy=0.5>,
     <tf.Tensor: shape=(), dtype=float64, numpy=-333008821.28051805>,
     <tf.Tensor: shape=(), dtype=float64, numpy=-4.440892098500626e-16>,
     <tf.Tensor: shape=(), dtype=float64, numpy=0.0>]



More human friendly output is generated by

.. code-block:: python

    print(exp.gateset.print_parameters(gateset_opt_map))


.. parsed-literal::

    X90p:Id-d1-gauss-amp        : 500.000 mV
    X90p:Id-d1-gauss-freq_offset: -53.000 MHz 2pi
    X90p:Id-d1-gauss-xy_angle   : -444.089 arad
    X90p:Id-d1-gauss-delta      : 0.000



.. code-block:: python

    from c3.optimizers.c1 import C1
    import c3.libraries.algorithms as algorithms

The C1 object will handle the optimization for us. As a fidelity
function we choose average fidelity as well as LBFG-S (a wrapper of the
scipy implementation) from our library. See those libraries for how
these functions are defined and how to supply your own, if necessary.

.. code-block:: python

    opt = C1(
        dir_path="/tmp/c3log/",
        fid_func=fidelities.average_infid_set,
        fid_subspace=["Q1", "Q2"],
        gateset_opt_map=gateset_opt_map,
        opt_gates=opt_gates,
        algorithm=algorithms.lbfgs,
        options={"maxfun" : 10},
        run_name="better_X90"
    )

Finally we supply our defined experiment.

.. code-block:: python

    opt.set_exp(exp)

Everything is in place to start the optimization.

.. code-block:: python

    opt.optimize_controls()






.. image:: output_84_1.png






.. image:: output_84_3.png





After a few steps we have improved the gate significantly, as we can
check with

.. code-block:: python

    opt.current_best_goal




.. parsed-literal::

    0.0006394



And by looking at the same sequences as before.

.. code-block:: python

    exp.plot_dynamics(init_state, barely_a_seq, debug=True)



.. image:: output_88_0.png


.. code-block:: python

    exp.plot_dynamics(init_state, barely_a_seq * 5, debug=True)



.. image:: output_89_0.png


Compared to before the optimization.

.. image:: dyn_5X.png
